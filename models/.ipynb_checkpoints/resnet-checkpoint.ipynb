{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2f0d23-75c3-4955-a3ff-9174ac46518b",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Imports '''\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils import data\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits import mplot3d\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils import data\n",
    "import itertools\n",
    "import re\n",
    "import random\n",
    "import time\n",
    "from torch.autograd import Variable\n",
    "import math\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from torch.autograd import Variable\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031d2932-4c2b-4214-a11d-99a803a646cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Train epoch function '''\n",
    "\n",
    "def train_epoch(train_loader, model, optimizer, loss_function):\n",
    "    train_mse = []\n",
    "\n",
    "    for xx, yy in train_loader:\n",
    "        \n",
    "        xx = xx.to(device)\n",
    "        yy = yy.to(device)\n",
    "\n",
    "        xx = xx.unsqueeze(1)\n",
    "        yy = yy.unsqueeze(1)\n",
    "\n",
    "        loss = 0\n",
    "        ims = []\n",
    "\n",
    "        for y in yy.transpose(0, 1):\n",
    "            y = y.unsqueeze(1)\n",
    "            im = model(xx)\n",
    "            # print(im.shape)\n",
    "            xx = torch.cat([xx[:, 2:], im], 1)\n",
    "            loss += loss_function(im, y)\n",
    "        \n",
    "        train_mse.append(loss.item()/yy.shape[1]) \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    train_mse = round(np.sqrt(np.mean(train_mse)),5)\n",
    "    return train_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e863e5-3a7e-4f75-957a-7dc30c7d1b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Eval epoch function '''\n",
    "\n",
    "def eval_epoch(valid_loader, model, loss_function):\n",
    "    valid_mse = []\n",
    "    preds = []\n",
    "    trues = []\n",
    "    with torch.no_grad():\n",
    "        for xx, yy in valid_loader:\n",
    "            xx = xx.to(device)\n",
    "            yy = yy.to(device)\n",
    "\n",
    "            xx = xx.unsqueeze(1)\n",
    "            yy = yy.unsqueeze(1)\n",
    "\n",
    "            loss = 0\n",
    "            ims = []\n",
    "            for y in yy.transpose(0, 1):\n",
    "                y = y.unsqueeze(1)\n",
    "                im = model(xx)\n",
    "                xx = torch.cat([xx[:, 2:], im], 1)\n",
    "                loss += loss_function(im, y)\n",
    "                ims.append(im.unsqueeze(1).cpu().data.numpy())\n",
    "                \n",
    "            ims = np.concatenate(ims, axis = 1)\n",
    "            preds.append(ims)\n",
    "            trues.append(yy.cpu().data.numpy())\n",
    "            valid_mse.append(loss.item()/yy.shape[1])\n",
    "        preds = np.concatenate(preds, axis = 0)  \n",
    "        trues = np.concatenate(trues, axis = 0)  \n",
    "        valid_mse = round(np.sqrt(np.mean(valid_mse)), 5)\n",
    "    return valid_mse, preds, trues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9de004-089a-4fe3-adfc-c6666b0dc8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Test epoch function '''\n",
    "\n",
    "def test_epoch(valid_loader, model, loss_function):\n",
    "    valid_mse = []\n",
    "    preds = []\n",
    "    trues = []\n",
    "    with torch.no_grad():\n",
    "        loss_curve = []\n",
    "        for xx, yy in valid_loader:\n",
    "            xx = xx.to(device)\n",
    "            yy = yy.to(device)\n",
    "\n",
    "            xx = xx.unsqueeze(1)\n",
    "            yy = yy.unsqueeze(1)\n",
    "\n",
    "            loss = 0\n",
    "            ims = []\n",
    "            \n",
    "            for y in yy.transpose(0, 1):\n",
    "                y = y.unsqueeze(1)\n",
    "                im = model(xx)\n",
    "                xx = torch.cat([xx[:, 2:], im], 1)\n",
    "                mse = loss_function(im, y)\n",
    "                loss += mse\n",
    "                loss_curve.append(mse.item())\n",
    "                ims.append(im.unsqueeze(1).cpu().data.numpy())\n",
    "           \n",
    "            ims = np.concatenate(ims, axis = 1)\n",
    "            preds.append(ims)\n",
    "            trues.append(yy.cpu().data.numpy())\n",
    "            valid_mse.append(loss.item()/yy.shape[1])\n",
    "            \n",
    "        loss_curve = np.array(loss_curve).reshape(-1,yy.shape[1])\n",
    "        preds = np.concatenate(preds, axis = 0)  \n",
    "        trues = np.concatenate(trues, axis = 0)  \n",
    "        valid_mse = np.mean(valid_mse)\n",
    "        loss_curve = np.sqrt(np.mean(loss_curve, axis = 0))\n",
    "    return valid_mse, preds, trues, loss_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229c1b04-fe69-452f-ab77-de435fe8152d",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Data Loader '''\n",
    "\n",
    "class Dataset(data.Dataset):\n",
    "    def __init__(self, indices, direc):\n",
    "        self.list_IDs = indices\n",
    "        self.direc = direc\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.list_IDs)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        ID = self.list_IDs[index]\n",
    "        \n",
    "        x = torch.load(self.direc + 'h_' + str(ID) + \".pt\")\n",
    "        y = torch.load(self.direc + 'T_' + str(ID) + \".pt\")\n",
    "        \n",
    "        return x.float(), y.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5052a0-f482-45c4-b0f2-a7a6c58222e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Dataset Parameters '''\n",
    "\n",
    "batch_size = 8\n",
    "train_direc = \"../simulated_data_reg/\"\n",
    "valid_direc = \"../simulated_data_reg/\"\n",
    "test_direc = \"../simulated_data_reg/\"\n",
    "train_indices = list(range(0, 300))\n",
    "valid_indices = list(range(300, 370))\n",
    "test_indices = list(range(370, 465))\n",
    "# train_indices = list(range(0, 200))\n",
    "# valid_indices = list(range(200, 250))\n",
    "# test_indices = list(range(250, 270))\n",
    "\n",
    "''' Load Data '''\n",
    "\n",
    "train_set = Dataset(train_indices, train_direc)\n",
    "valid_set = Dataset(valid_indices, valid_direc)\n",
    "test_set = Dataset(test_indices, test_direc)\n",
    "\n",
    "train_loader = data.DataLoader(train_set, batch_size = batch_size, shuffle = True, num_workers = 8)\n",
    "valid_loader = data.DataLoader(valid_set, batch_size = batch_size, shuffle = True, num_workers = 8)\n",
    "test_loader = data.DataLoader(test_set, batch_size = batch_size, shuffle = False, num_workers = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bb6539-6f5d-41af-bc7b-0962a3ea7abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Model Hyperparameters '''\n",
    "\n",
    "n_epochs = 60\n",
    "learning_rate = 0.001\n",
    "lr_decay = 0.9\n",
    "\n",
    "min_mse = 100\n",
    "train_mse = []\n",
    "valid_mse = []\n",
    "test_mse = []\n",
    "times = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e56054f-b19b-4e0c-876e-cfbe531a6cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' ResNet '''\n",
    "\n",
    "class Resblock(nn.Module):\n",
    "    def __init__(self, input_channels, hidden_dim, kernel_size):\n",
    "        super(Resblock, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(input_channels, hidden_dim, kernel_size = kernel_size, padding = (kernel_size-1)//2),\n",
    "            nn.BatchNorm2d(hidden_dim),\n",
    "            nn.LeakyReLU(0.5)\n",
    "        ) \n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(hidden_dim, hidden_dim, kernel_size = kernel_size, padding = (kernel_size-1)//2),\n",
    "            nn.BatchNorm2d(hidden_dim),\n",
    "            nn.LeakyReLU(0.5)\n",
    "        ) \n",
    "        \n",
    "        if input_channels != hidden_dim:\n",
    "            self.upscale = nn.Sequential(\n",
    "                nn.Conv2d(input_channels, hidden_dim, kernel_size = kernel_size, padding = (kernel_size-1)//2),\n",
    "                nn.LeakyReLU(0.5)\n",
    "                )        \n",
    "        self.input_channels = input_channels\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        \n",
    "    def forward(self, xx):\n",
    "        out = self.layer1(xx)  \n",
    "        if self.input_channels != self.hidden_dim:\n",
    "            out = self.layer2(out) + self.upscale(xx)\n",
    "        else:\n",
    "            out = self.layer2(out) + xx\n",
    "        return out\n",
    "    \n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, input_channels, output_channels, kernel_size):\n",
    "        super(ResNet, self).__init__()\n",
    "        layers = [Resblock(input_channels, 64, kernel_size), Resblock(64, 64, kernel_size)]\n",
    "        layers += [Resblock(64, 128, kernel_size), Resblock(128, 128, kernel_size)]\n",
    "        layers += [Resblock(128, 300, kernel_size), Resblock(300, 300, kernel_size)]\n",
    "        layers += [nn.Conv2d(300, output_channels, kernel_size = kernel_size, padding = (kernel_size-1)//2)]\n",
    "        # layers += [Resblock(256, 512, kernel_size), Resblock(512, 512, kernel_size)]\n",
    "        # layers += [nn.Conv2d(512, output_channels, kernel_size = kernel_size, padding = (kernel_size-1)//2)]\n",
    "        self.model = nn.Sequential(*layers)\n",
    "             \n",
    "    def forward(self, xx):\n",
    "        out = self.model(xx)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb19544-d036-49be-9d2b-069f54f174c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Model '''\n",
    "\n",
    "model = nn.DataParallel(ResNet(input_channels = 1, output_channels = 1, kernel_size = 3).to(device))\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), learning_rate,betas=(learning_rate, 0.999), weight_decay=4e-4)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size= 1, gamma=lr_decay)\n",
    "loss_fun = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b8d421-5d7a-4d1d-b300-1321f623275b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Parameters: ', sum(p.numel() for p in model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9cd1dae-9b7c-4266-8c58-991d9cf0789c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in tqdm(range(n_epochs)):\n",
    "\n",
    "    print('EPOCH: ', i+1)\n",
    "\n",
    "    start = time.time()\n",
    "    scheduler.step()\n",
    "\n",
    "    model.train()\n",
    "    print('Model trained')\n",
    "\n",
    "    train_mse.append(train_epoch(train_loader, model, optimizer, loss_fun))\n",
    "    model.eval()\n",
    "    mse, _, _ = eval_epoch(valid_loader, model, loss_fun)\n",
    "    valid_mse.append(mse)\n",
    "    \n",
    "    if valid_mse[-1] < min_mse:\n",
    "        min_mse = valid_mse[-1] \n",
    "        best_model = model\n",
    "\n",
    "    end = time.time()\n",
    "    \n",
    "    times.append(end-start)\n",
    "    \n",
    "    # Early Stopping but train at least for 50 epochs\n",
    "    # if (len(train_mse) > 50 and np.mean(valid_mse[-5:]) >= np.mean(valid_mse[-10:-5])):\n",
    "    #         break\n",
    "            \n",
    "    print('TRAIN MSE: ', train_mse[-1])\n",
    "    print('VALID MSE: ', valid_mse[-1])\n",
    "    print('TIME: ', end - start)\n",
    "    print('----------------------------------')\n",
    "\n",
    "test_mse, preds, trues, loss_curve = test_epoch(test_loader, best_model, loss_fun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e394cf00-0b6e-465b-be84-c15485946ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Plot Loss Curves '''\n",
    "\n",
    "plt.plot(train_mse, label='Train')\n",
    "plt.plot(valid_mse, label='Valid')\n",
    "plt.xlabel('Epoch #')\n",
    "plt.ylabel('MSE')\n",
    "plt.title('MSE')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a9c7f2-7f99-49f3-b07e-4fe839436061",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.load('../simulated_data_reg/h_0.pt')\n",
    "y = torch.load('../simulated_data_reg/T_0.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4a1da4-1de9-45ab-af3f-0f4fbd7defb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' EDA '''\n",
    "\n",
    "row = 100\n",
    "\n",
    "output = model(x.unsqueeze(0).unsqueeze(0).to(device))\n",
    "output = output.squeeze(0).squeeze(0)\n",
    "\n",
    "plt.hist(x[row].cpu().detach().numpy(), color = \"blue\", label=\"height\")\n",
    "plt.hist(y[row].cpu().detach().numpy(), color = \"red\", label=\"original temperature\")\n",
    "plt.hist(output[row].cpu().detach().numpy(), color = \"green\", label=\"output temperature\")\n",
    "plt.title('Row ' + str(row))    \n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e61054c-96b4-476b-830f-c960c6f2e2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Visualize model output '''\n",
    "\n",
    "height = x.numpy()\n",
    "plt.imshow(height, cmap='hot', interpolation='nearest')\n",
    "plt.title('Height profile')\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "original_temperature = y.numpy()\n",
    "plt.imshow(original_temperature, cmap='hot', interpolation='nearest')\n",
    "plt.title('Original temperature profile')\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "output = model(x.unsqueeze(0).unsqueeze(0).to(device))\n",
    "output = output.squeeze(0).squeeze(0)\n",
    "output = output.cpu().detach().numpy()\n",
    "plt.imshow(output, cmap='hot', interpolation='nearest')\n",
    "plt.title('Predicted temperature profile')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce1289f-a4fb-4086-b0dc-b781b2fbb25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_and_metrics_dict = {}\n",
    "model_and_metrics_dict['train_mse'] = train_mse\n",
    "model_and_metrics_dict['valid_mse'] = valid_mse\n",
    "model_and_metrics_dict['test_mse'] = test_mse\n",
    "model_and_metrics_dict['epochs'] = n_epochs\n",
    "model_and_metrics_dict['learning_rate'] = learning_rate\n",
    "model_and_metrics_dict['model'] = 'cnn'\n",
    "model_and_metrics_dict['time'] = times\n",
    "\n",
    "print(model_and_metrics_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7d9801-be42-4aa8-b1be-931843048c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"../trained_models/resnet_backward.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734801b0-cf3e-4651-b5de-c1403e418b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../metrics/resnet_backward.json', 'w') as f:\n",
    "    json.dump(model_and_metrics_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e6a61a-de4f-40e7-bc15-8a7fbdd7a674",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
