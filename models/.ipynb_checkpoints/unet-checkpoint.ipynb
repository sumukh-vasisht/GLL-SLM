{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8a2cb8-885c-432d-aa78-a112a3db4d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Imports '''\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils import data\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits import mplot3d\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils import data\n",
    "import itertools\n",
    "import re\n",
    "import random\n",
    "import time\n",
    "from torch.autograd import Variable\n",
    "import math\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from torch.autograd import Variable\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d042e02-38fd-402d-8b56-a6457f9cb910",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Train epoch function '''\n",
    "\n",
    "def train_epoch(train_loader, model, optimizer, loss_function):\n",
    "    train_mse = []\n",
    "\n",
    "    for xx, yy in train_loader:\n",
    "        \n",
    "        xx = xx.to(device)\n",
    "        yy = yy.to(device)\n",
    "\n",
    "        xx = xx.unsqueeze(1)\n",
    "        yy = yy.unsqueeze(1)\n",
    "\n",
    "        loss = 0\n",
    "        ims = []\n",
    "\n",
    "        for y in yy.transpose(0, 1):\n",
    "            y = y.unsqueeze(1)\n",
    "            im = model(xx)\n",
    "            # print(im.shape)\n",
    "            xx = torch.cat([xx[:, 2:], im], 1)\n",
    "            loss += loss_function(im, y)\n",
    "        \n",
    "        train_mse.append(loss.item()/yy.shape[1]) \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    train_mse = round(np.sqrt(np.mean(train_mse)),5)\n",
    "    return train_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776d4bbd-dabd-4672-a674-df3a2efcbb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Eval epoch function '''\n",
    "\n",
    "def eval_epoch(valid_loader, model, loss_function):\n",
    "    valid_mse = []\n",
    "    preds = []\n",
    "    trues = []\n",
    "    with torch.no_grad():\n",
    "        for xx, yy in valid_loader:\n",
    "            xx = xx.to(device)\n",
    "            yy = yy.to(device)\n",
    "\n",
    "            xx = xx.unsqueeze(1)\n",
    "            yy = yy.unsqueeze(1)\n",
    "\n",
    "            loss = 0\n",
    "            ims = []\n",
    "            for y in yy.transpose(0, 1):\n",
    "                y = y.unsqueeze(1)\n",
    "                im = model(xx)\n",
    "                xx = torch.cat([xx[:, 2:], im], 1)\n",
    "                loss += loss_function(im, y)\n",
    "                ims.append(im.unsqueeze(1).cpu().data.numpy())\n",
    "                \n",
    "            ims = np.concatenate(ims, axis = 1)\n",
    "            preds.append(ims)\n",
    "            trues.append(yy.cpu().data.numpy())\n",
    "            valid_mse.append(loss.item()/yy.shape[1])\n",
    "        preds = np.concatenate(preds, axis = 0)  \n",
    "        trues = np.concatenate(trues, axis = 0)  \n",
    "        valid_mse = round(np.sqrt(np.mean(valid_mse)), 5)\n",
    "    return valid_mse, preds, trues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fa767e-2afb-48f0-9c30-64c7b0dc45f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Test epoch function '''\n",
    "\n",
    "def test_epoch(valid_loader, model, loss_function):\n",
    "    valid_mse = []\n",
    "    preds = []\n",
    "    trues = []\n",
    "    with torch.no_grad():\n",
    "        loss_curve = []\n",
    "        for xx, yy in valid_loader:\n",
    "            xx = xx.to(device)\n",
    "            yy = yy.to(device)\n",
    "\n",
    "            xx = xx.unsqueeze(1)\n",
    "            yy = yy.unsqueeze(1)\n",
    "\n",
    "            loss = 0\n",
    "            ims = []\n",
    "            \n",
    "            for y in yy.transpose(0, 1):\n",
    "                y = y.unsqueeze(1)\n",
    "                im = model(xx)\n",
    "                xx = torch.cat([xx[:, 2:], im], 1)\n",
    "                mse = loss_function(im, y)\n",
    "                loss += mse\n",
    "                loss_curve.append(mse.item())\n",
    "                ims.append(im.unsqueeze(1).cpu().data.numpy())\n",
    "           \n",
    "            ims = np.concatenate(ims, axis = 1)\n",
    "            preds.append(ims)\n",
    "            trues.append(yy.cpu().data.numpy())\n",
    "            valid_mse.append(loss.item()/yy.shape[1])\n",
    "            \n",
    "        loss_curve = np.array(loss_curve).reshape(-1,yy.shape[1])\n",
    "        preds = np.concatenate(preds, axis = 0)  \n",
    "        trues = np.concatenate(trues, axis = 0)  \n",
    "        valid_mse = np.mean(valid_mse)\n",
    "        loss_curve = np.sqrt(np.mean(loss_curve, axis = 0))\n",
    "    return valid_mse, preds, trues, loss_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621616ac-0664-4aed-a7ab-5eaa71588413",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Data Loader '''\n",
    "\n",
    "class Dataset(data.Dataset):\n",
    "    def __init__(self, indices, direc):\n",
    "        self.list_IDs = indices\n",
    "        self.direc = direc\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.list_IDs)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        ID = self.list_IDs[index]\n",
    "        \n",
    "        x = torch.load(self.direc + 'h_' + str(ID) + \".pt\")\n",
    "        y = torch.load(self.direc + 'T_' + str(ID) + \".pt\")\n",
    "        \n",
    "        return x.float(), y.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7c996c-ebd0-4369-8f9d-4ad1dddb90f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Dataset Parameters '''\n",
    "\n",
    "batch_size = 8\n",
    "train_direc = \"../simulated_data_reg/\"\n",
    "valid_direc = \"../simulated_data_reg/\"\n",
    "test_direc = \"../simulated_data_reg/\"\n",
    "train_indices = list(range(0, 300))\n",
    "valid_indices = list(range(300, 370))\n",
    "test_indices = list(range(370, 465))\n",
    "# train_indices = list(range(0, 200))\n",
    "# valid_indices = list(range(200, 250))\n",
    "# test_indices = list(range(250, 270))\n",
    "\n",
    "''' Load Data '''\n",
    "\n",
    "train_set = Dataset(train_indices, train_direc)\n",
    "valid_set = Dataset(valid_indices, valid_direc)\n",
    "test_set = Dataset(test_indices, test_direc)\n",
    "\n",
    "train_loader = data.DataLoader(train_set, batch_size = batch_size, shuffle = True, num_workers = 8)\n",
    "valid_loader = data.DataLoader(valid_set, batch_size = batch_size, shuffle = True, num_workers = 8)\n",
    "test_loader = data.DataLoader(test_set, batch_size = batch_size, shuffle = False, num_workers = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ffd0f5-1b20-44b4-a6fb-56e7c518fe3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Model Hyperparameters '''\n",
    "\n",
    "n_epochs = 60\n",
    "learning_rate = 0.001\n",
    "lr_decay = 0.9\n",
    "\n",
    "min_mse = 100\n",
    "train_mse = []\n",
    "valid_mse = []\n",
    "test_mse = []\n",
    "times = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7bdc3a-5d75-400c-b855-0e6d71429e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' U-Net '''\n",
    "\n",
    "def conv(input_channels, output_channels, kernel_size, stride):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(input_channels, output_channels, kernel_size = kernel_size,\n",
    "                  stride = stride, padding=(kernel_size - 1) // 2),\n",
    "        nn.BatchNorm2d(output_channels),\n",
    "        nn.LeakyReLU(0.5, inplace = True)\n",
    "    )\n",
    "\n",
    "def deconv(input_channels, output_channels):\n",
    "    return nn.Sequential(\n",
    "        nn.ConvTranspose2d(input_channels, output_channels, kernel_size = 4,\n",
    "                           stride = 2, padding=1),\n",
    "        nn.LeakyReLU(0.5, inplace=True)\n",
    "    )\n",
    "\n",
    "class Unet(nn.Module):\n",
    "    def __init__(self, input_channels, output_channels, kernel_size):\n",
    "        super(Unet, self).__init__()\n",
    "        self.input_channels = input_channels\n",
    "        self.conv1 = conv(input_channels, 64, kernel_size=kernel_size, stride=1)\n",
    "        self.conv2 = conv(64, 128, kernel_size=kernel_size, stride=1)\n",
    "        self.conv2_1 = conv(128, 128, kernel_size=kernel_size, stride=1)\n",
    "        self.conv3 = conv(128, 256, kernel_size=kernel_size, stride=2)\n",
    "        self.conv3_1 = conv(256, 256, kernel_size=kernel_size, stride=2)\n",
    "        self.conv4 = conv(256, 256, kernel_size=kernel_size, stride=1)\n",
    "        self.conv4_1 = conv(256, 256, kernel_size=kernel_size, stride=2)\n",
    "\n",
    "        self.deconv3 = deconv(256, 128)\n",
    "        self.deconv2 = deconv(256, 64)\n",
    "        self.deconv1 = deconv(192, 32)\n",
    "        self.deconv0 = deconv(96, 16)\n",
    "        \n",
    "        self.output_layer = nn.Conv2d(16 + input_channels, output_channels, kernel_size=kernel_size,\n",
    "                                      stride = 1, padding=(kernel_size - 1) // 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out_conv1 = self.conv1(x)\n",
    "        print('out_conv1: ', out_conv1.shape)\n",
    "        out_conv2 = self.conv2_1(self.conv2(out_conv1))\n",
    "        print('out_conv2: ', out_conv2.shape)\n",
    "        out_conv3 = self.conv3_1(self.conv3(out_conv2))\n",
    "        print('out_conv3: ', out_conv3.shape)\n",
    "        out_conv4 = self.conv4_1(self.conv4(out_conv3))\n",
    "        print('out_conv4: ', out_conv4.shape)\n",
    "\n",
    "        out_deconv3 = self.deconv3(out_conv4)\n",
    "        print('out_deconv3: ', out_deconv3.shape)\n",
    "        concat3 = torch.cat((out_conv3, out_deconv3), 1)\n",
    "        print('concat3: ', concat3.shape)\n",
    "        out_deconv2 = self.deconv2(out_conv3)\n",
    "        print('out_deconv2: ', out_deconv2.shape)\n",
    "        concat2 = torch.cat((out_conv2, out_deconv2), 1)\n",
    "        print('concat2: ', concat2.shape)\n",
    "        out_deconv1 = self.deconv1(concat2)\n",
    "        print('out_deconv1: ', out_deconv1.shape)\n",
    "        concat1 = torch.cat((out_conv1, out_deconv1), 1)\n",
    "        print('concat1: ', concat1.shape)\n",
    "        out_deconv0 = self.deconv0(concat1)\n",
    "        print('out_deconv0: ', out_deconv0.shape)\n",
    "        concat0 = torch.cat((x, out_deconv0), 1)\n",
    "        print('concat0: ', concat0.shape)\n",
    "        out = self.output_layer(concat0)\n",
    "        print('out: ', out.shape)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84ff090-42ba-47da-b960-649590ca3f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Model '''\n",
    "\n",
    "model = nn.DataParallel(Unet(input_channels = 1, output_channels = 1, kernel_size = 3).to(device))\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), learning_rate,betas=(learning_rate, 0.999), weight_decay=4e-4)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size= 1, gamma=lr_decay)\n",
    "loss_fun = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e618b48-005f-4b5b-aefd-1fa2cf384270",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(model, (1, 200, 200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7837702b-cde9-4d96-840b-69e8e497b204",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Parameters: ', sum(p.numel() for p in model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8846e7e2-ca14-404f-84a6-97817987e0c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in tqdm(range(n_epochs)):\n",
    "\n",
    "    print('EPOCH: ', i+1)\n",
    "\n",
    "    start = time.time()\n",
    "    scheduler.step()\n",
    "\n",
    "    model.train()\n",
    "    print('Model trained')\n",
    "\n",
    "    train_mse.append(train_epoch(train_loader, model, optimizer, loss_fun))\n",
    "    model.eval()\n",
    "    mse, _, _ = eval_epoch(valid_loader, model, loss_fun)\n",
    "    valid_mse.append(mse)\n",
    "    \n",
    "    if valid_mse[-1] < min_mse:\n",
    "        min_mse = valid_mse[-1] \n",
    "        best_model = model\n",
    "\n",
    "    end = time.time()\n",
    "    \n",
    "    times.append(end-start)\n",
    "    \n",
    "    # Early Stopping but train at least for 50 epochs\n",
    "    # if (len(train_mse) > 50 and np.mean(valid_mse[-5:]) >= np.mean(valid_mse[-10:-5])):\n",
    "    #         break\n",
    "            \n",
    "    print('TRAIN MSE: ', train_mse[-1])\n",
    "    print('VALID MSE: ', valid_mse[-1])\n",
    "    print('TIME: ', end - start)\n",
    "    print('----------------------------------')\n",
    "\n",
    "test_mse, preds, trues, loss_curve = test_epoch(test_loader, best_model, loss_fun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1477e6-d0d6-43bc-a867-e81d14b601e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Plot Loss Curves '''\n",
    "\n",
    "plt.plot(train_mse, label='Train')\n",
    "plt.plot(valid_mse, label='Valid')\n",
    "plt.xlabel('Epoch #')\n",
    "plt.ylabel('MSE')\n",
    "plt.title('MSE')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935263d6-087b-4e71-a70b-b361db60ba63",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.load('../simulated_data_reg/h_0.pt')\n",
    "y = torch.load('../simulated_data_reg/T_0.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2138ee9f-5688-46ad-89c8-7dccbb00e71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' EDA '''\n",
    "\n",
    "row = 100\n",
    "\n",
    "output = model(x.unsqueeze(0).unsqueeze(0).to(device))\n",
    "output = output.squeeze(0).squeeze(0)\n",
    "\n",
    "plt.hist(x[row].cpu().detach().numpy(), color = \"blue\", label=\"height\")\n",
    "plt.hist(y[row].cpu().detach().numpy(), color = \"red\", label=\"original temperature\")\n",
    "plt.hist(output[row].cpu().detach().numpy(), color = \"green\", label=\"output temperature\")\n",
    "plt.title('Row ' + str(row))    \n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ae05a9-3782-4449-ad35-f9e59f1262a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Visualize model output '''\n",
    "\n",
    "height = x.numpy()\n",
    "plt.imshow(height, cmap='hot', interpolation='nearest')\n",
    "plt.title('Height profile')\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "original_temperature = y.numpy()\n",
    "plt.imshow(original_temperature, cmap='hot', interpolation='nearest')\n",
    "plt.title('Original temperature profile')\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "output = model(x.unsqueeze(0).unsqueeze(0).to(device))\n",
    "output = output.squeeze(0).squeeze(0)\n",
    "output = output.cpu().detach().numpy()\n",
    "plt.imshow(output, cmap='hot', interpolation='nearest')\n",
    "plt.title('Predicted temperature profile')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47cf7f23-377c-4e4f-abb0-7dddf9bd650d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_and_metrics_dict = {}\n",
    "model_and_metrics_dict['train_mse'] = train_mse\n",
    "model_and_metrics_dict['valid_mse'] = valid_mse\n",
    "model_and_metrics_dict['test_mse'] = test_mse\n",
    "model_and_metrics_dict['epochs'] = n_epochs\n",
    "model_and_metrics_dict['learning_rate'] = learning_rate\n",
    "model_and_metrics_dict['model'] = 'cnn'\n",
    "model_and_metrics_dict['time'] = times\n",
    "\n",
    "print(model_and_metrics_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29219d5-eb94-4fee-82cb-7e098144d40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"../trained_models/unet_backward.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05293508-6626-45ad-bf5e-efed968ade0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../metrics/unet_backward.json', 'w') as f:\n",
    "    json.dump(model_and_metrics_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1831dbe5-d666-4ffa-ac46-04b02ea189bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
