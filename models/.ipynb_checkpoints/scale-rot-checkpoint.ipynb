{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9d6be3-c259-4ca8-8d3d-8a79a2ba2a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import e2cnn\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from e2cnn.nn.modules.r2_conv.r2convolution import compute_basis_params\n",
    "from e2cnn.nn.modules.r2_conv.basisexpansion_singleblock import block_basisexpansion\n",
    "import warnings\n",
    "\n",
    "from torch.utils import data\n",
    "from torchsummary import summary\n",
    "\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43460b4-cb8a-44b5-98ef-78b288ec23b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale and Rotation Equivariant Layer\n",
    "class ScaleRotEquivLayer(torch.nn.Module):\n",
    "    def __init__(self, \n",
    "                 in_frames, # number of input frames\n",
    "                 out_frames, # number of output frames\n",
    "                 kernel_size, \n",
    "                 N, # Order of rotation group\n",
    "                 scale_factors, # scaling factors applied to equivariant basis\n",
    "                 first_layer = False, # whether it is the first layer\n",
    "                 last_layer = False # whether it is the last layer\n",
    "                ):\n",
    "        super(ScaleRotEquivLayer, self).__init__()\n",
    "        \n",
    "        r2_act = e2cnn.gspaces.Rot2dOnR2(N = N)\n",
    "        self.last_layer = last_layer\n",
    "        self.first_layer = first_layer\n",
    "        self.kernel_size = kernel_size\n",
    "        \n",
    "        if self.first_layer:\n",
    "            self.feat_type_in = e2cnn.nn.FieldType(r2_act, in_frames*[r2_act.trivial_repr])\n",
    "        else:\n",
    "            self.feat_type_in = e2cnn.nn.FieldType(r2_act, in_frames*[r2_act.regular_repr])\n",
    "            \n",
    "        if self.last_layer:\n",
    "            self.feat_type_hid = e2cnn.nn.FieldType(r2_act, out_frames*[r2_act.trivial_repr])\n",
    "        else:\n",
    "            self.feat_type_hid = e2cnn.nn.FieldType(r2_act, out_frames*[r2_act.regular_repr])\n",
    "            \n",
    "        \n",
    "        if not last_layer:\n",
    "            self.norm = e2cnn.nn.InnerBatchNorm(self.feat_type_hid)\n",
    "            self.relu = e2cnn.nn.ReLU(self.feat_type_hid)\n",
    "        \n",
    "        # obtain the equivariant basis kernels\n",
    "        grid, basis_filter, rings, sigma, maximum_frequency = compute_basis_params(kernel_size = kernel_size)\n",
    "        i_repr = self.feat_type_in._unique_representations.pop()\n",
    "        o_repr = self.feat_type_hid._unique_representations.pop()\n",
    "        basis = self.feat_type_in.gspace.build_kernel_basis(i_repr, o_repr, sigma, rings, maximum_frequency = 5)\n",
    "        block_expansion = block_basisexpansion(basis, grid, basis_filter, recompute=False)\n",
    "        basis_kernels = block_expansion.sampled_basis.to(device)\n",
    "        \n",
    "        \n",
    "        basis_kernels = basis_kernels.transpose(0,1).transpose(1,2) \n",
    "        basis_kernels = basis_kernels.reshape(basis_kernels.shape[0], \n",
    "                                              basis_kernels.shape[1],\n",
    "                                              basis_kernels.shape[2], \n",
    "                                              kernel_size, kernel_size)\n",
    "        # basis_kernels size: out_chs x inp_chs x number of basis x kz x kz\n",
    "        \n",
    "        # apply scaling transformations\n",
    "        self.multiscale_basis_kernels = torch.cat([self.resize_conv_kernel(basis_kernels, f) for f in scale_factors], dim=2)\n",
    "        \n",
    "        # initialize weights and biases\n",
    "        stdv = np.sqrt(1/(in_frames*kernel_size*kernel_size))\n",
    "        self.weights = nn.Parameter(torch.ones(out_frames, in_frames, self.multiscale_basis_kernels.shape[2]).float().to(device))\n",
    "        self.weights.data.uniform_(-stdv, stdv)\n",
    "\n",
    "        self.bias = nn.Parameter(torch.zeros(out_frames*self.multiscale_basis_kernels.shape[0]).to(device))\n",
    "        self.bias.data.uniform_(-stdv, stdv)\n",
    "        \n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # multiply equivariant basis by trainable weights  \n",
    "        conv_filters = torch.einsum('pqbkl,oib->opiqkl', \n",
    "                                    self.multiscale_basis_kernels.to(self.weights.device), \n",
    "                                    self.weights) \n",
    "        \n",
    "        conv_filters = conv_filters.reshape(conv_filters.shape[0]*conv_filters.shape[1],\n",
    "                                            conv_filters.shape[2]*conv_filters.shape[3], \n",
    "                                            self.kernel_size, self.kernel_size)\n",
    "        \n",
    "        if not self.last_layer:\n",
    "            out = F.conv2d(x, conv_filters, self.bias, padding = (self.kernel_size - 1)//2)\n",
    "            return self.relu(e2cnn.nn.GeometricTensor(out, self.feat_type_hid)).tensor\n",
    "        else:\n",
    "            return F.conv2d(x, conv_filters, self.bias, padding = (self.kernel_size - 1)//2)\n",
    "        \n",
    "        \n",
    "    def resize_conv_kernel(self,\n",
    "                       kernel, # a PyTorch tensor of shape (#basis, kernel_size, kernel_size)\n",
    "                       scale_factor, # scaling factors for two spatial dims\n",
    "                       mode='trilinear' #interpolation mode to use for resizing\n",
    "                      ):\n",
    "    \n",
    "        # get the original kernel size\n",
    "        old_size = kernel.size(-1)\n",
    "        \n",
    "        # resize the kernel using bilinear interpolation\n",
    "        resized_kernel = F.interpolate(kernel, scale_factor = (1, scale_factor, scale_factor), mode=mode)\n",
    "        new_size = resized_kernel.size(-1)\n",
    "\n",
    "        if scale_factor < 1:\n",
    "            # adjust the kernel size to match the new size\n",
    "            new_kernel = torch.zeros(kernel.shape).to(device)\n",
    "            padding = (old_size - resized_kernel.shape[-1]) // 2 \n",
    "            new_kernel[..., padding:padding+new_size, padding:padding+new_size] = resized_kernel\n",
    "        else:\n",
    "            padding = (resized_kernel.shape[-1] - old_size) // 2 \n",
    "            new_kernel = resized_kernel[..., padding:padding+old_size, padding:padding+old_size]\n",
    "\n",
    "        return new_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de4418f-d2a2-422f-847a-122af1ad06f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale and Rotation Equivariant ResNet Block\n",
    "class ScaleRotEquivResBlock(torch.nn.Module):\n",
    "    def __init__(self, \n",
    "                 in_frames,\n",
    "                 out_frames,\n",
    "                 kernel_size, \n",
    "                 N,\n",
    "                 scale_factors, \n",
    "                ): \n",
    "        super(ScaleRotEquivResBlock, self).__init__()\n",
    "        \n",
    "        self.layer1 = ScaleRotEquivLayer(in_frames = in_frames, \n",
    "                                         out_frames = out_frames,\n",
    "                                         kernel_size = kernel_size,\n",
    "                                         N = N, \n",
    "                                         scale_factors = scale_factors\n",
    "                                        )\n",
    "\n",
    "        \n",
    "        self.layer2 = ScaleRotEquivLayer(in_frames = out_frames, \n",
    "                                         out_frames = out_frames,\n",
    "                                         kernel_size = kernel_size,\n",
    "                                         N = N, \n",
    "                                         scale_factors = scale_factors\n",
    "                                        )\n",
    "\n",
    "        self.upscale = ScaleRotEquivLayer(in_frames = in_frames, \n",
    "                                         out_frames = out_frames,\n",
    "                                         kernel_size = kernel_size,\n",
    "                                         N = N, \n",
    "                                         scale_factors = scale_factors\n",
    "                                        )\n",
    "\n",
    "        \n",
    "        self.in_frames = in_frames\n",
    "        self.out_frames = out_frames\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        \n",
    "        # residual connection\n",
    "        if self.in_frames != self.out_frames:\n",
    "            out = self.layer2(out) + self.upscale(x)\n",
    "        else:\n",
    "            out = self.layer2(out) + x\n",
    "            \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c01068-29e2-4196-b9dd-7b8fd3d78fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale and Rotation Equivariant ResNet\n",
    "class ScaleRotEquivResNet(torch.nn.Module):\n",
    "    def __init__(self, \n",
    "                 in_frames, \n",
    "                 out_frames,\n",
    "                 kernel_size, \n",
    "                 N, \n",
    "                 scale_factors):\n",
    "        \n",
    "        super(ScaleRotEquivResNet, self).__init__()\n",
    "        \n",
    "        self.input_layer = ScaleRotEquivLayer(in_frames = in_frames, \n",
    "                                              out_frames = 16,\n",
    "                                              kernel_size = kernel_size,\n",
    "                                              N = N, \n",
    "                                              scale_factors = scale_factors,\n",
    "                                              first_layer = True\n",
    "                                             )\n",
    "        \n",
    "        self.last_layer = ScaleRotEquivLayer(in_frames = 1024, \n",
    "                                              out_frames = out_frames,\n",
    "                                              kernel_size = kernel_size,\n",
    "                                              N = N, \n",
    "                                              scale_factors = scale_factors,\n",
    "                                              last_layer = True\n",
    "                                             )\n",
    "        \n",
    "        layers = [self.input_layer]\n",
    "        layers += [ScaleRotEquivResBlock(16, 32, kernel_size, N, scale_factors), \n",
    "                   ScaleRotEquivResBlock(32, 32, kernel_size, N, scale_factors)]\n",
    "        layers += [ScaleRotEquivResBlock(32, 64, kernel_size, N, scale_factors),\n",
    "                   ScaleRotEquivResBlock(64, 64, kernel_size, N, scale_factors)]\n",
    "        layers += [ScaleRotEquivResBlock(64, 128, kernel_size, N, scale_factors), \n",
    "                   ScaleRotEquivResBlock(128, 128, kernel_size, N, scale_factors)]\n",
    "        layers += [ScaleRotEquivResBlock(128, 256, kernel_size, N, scale_factors), \n",
    "                   ScaleRotEquivResBlock(256, 256, kernel_size, N, scale_factors)]\n",
    "        layers += [ScaleRotEquivResBlock(256, 512, kernel_size, N, scale_factors), \n",
    "                   ScaleRotEquivResBlock(512, 512, kernel_size, N, scale_factors)]\n",
    "        layers += [ScaleRotEquivResBlock(512, 1024, kernel_size, N, scale_factors), \n",
    "                   ScaleRotEquivResBlock(1024, 1024, kernel_size, N, scale_factors)]\n",
    "        layers += [self.last_layer]\n",
    "        self.model = torch.nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        #BxCxHxW\n",
    "        out = self.model(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb06152b-6524-4364-984e-49fc8dde0133",
   "metadata": {},
   "source": [
    "<h2>DATA LOADER</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c80e87d-4b43-4e5f-9a4b-38983b8dc838",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(data.Dataset):\n",
    "    def __init__(self, indices, direc):\n",
    "        self.list_IDs = indices\n",
    "        self.direc = direc\n",
    "      \n",
    "    def __len__(self):\n",
    "        return len(self.list_IDs)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        ID = self.list_IDs[index]\n",
    "        x = torch.load(self.direc + 'h_' + str(ID) + '.pt')\n",
    "        y = torch.load(self.direc + 'T_' + str(ID) + '.pt')\n",
    "            \n",
    "        return x.float(), y.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c11bc4a-4563-4e43-888c-5aa45ba48d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "\n",
    "print(batch_size)\n",
    "\n",
    "train_direc = '../simulated_data_reg/'\n",
    "valid_direc = '../simulated_data_reg/'\n",
    "test_direc = '../simulated_data_reg/'\n",
    "\n",
    "train_indices = list(range(0, 1))\n",
    "valid_indices = list(range(0, 1))\n",
    "test_indices = list(range(0, 1))\n",
    "\n",
    "''' Load Data '''\n",
    "\n",
    "train_set = Dataset(train_indices, train_direc)\n",
    "valid_set = Dataset(valid_indices, valid_direc)\n",
    "test_set = Dataset(test_indices, test_direc)\n",
    "\n",
    "train_loader = data.DataLoader(train_set, batch_size = batch_size, shuffle = True, num_workers = 0)\n",
    "valid_loader = data.DataLoader(valid_set, batch_size = batch_size, shuffle = True, num_workers = 0)\n",
    "test_loader = data.DataLoader(test_set, batch_size = batch_size, shuffle = False, num_workers = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a957c2-cf87-4fc6-b9be-a9282047e471",
   "metadata": {},
   "source": [
    "<h2>LOAD MODEL</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a368b77f-5572-459d-8a4f-cfbbfef74f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ScaleRotEquivResNet(in_frames = 1, \n",
    "                            out_frames = 1,\n",
    "                            kernel_size = 5,\n",
    "                            N = 4, \n",
    "                            scale_factors = [0.5, 0.75, 1, 1.5, 2]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7a8cd7-ca8e-4fee-b663-dccfa72e5e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(1, 1, 200, 200).to(device)\n",
    "print(model(x).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b1a01d-22b3-4c89-bc7c-24d0b426a70b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "summary(model, (1, 200, 200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaea1edc-88d3-4443-bc37-b8d2e886bd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = 'adam'\n",
    "lr = 0.01\n",
    "lr_gamma = 0.1\n",
    "\n",
    "data_dir = '../simulated_data_scale'\n",
    "\n",
    "parameters = filter(lambda x: x.requires_grad, model.parameters())\n",
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9354fe-88bf-4a3a-8a44-ac62eb5669d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if optimizer == 'adam':\n",
    "    optimizer = optim.Adam(parameters, lr=lr)\n",
    "    \n",
    "loss_fun = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385dfa19-0082-4c30-b256-e43cd4ed5385",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Train epoch function '''\n",
    "\n",
    "def train_epoch(train_loader, model, optimizer, loss_function):\n",
    "    train_mse = []\n",
    "    for xx, yy in train_loader:\n",
    "        xx = xx.to(device)\n",
    "        yy = yy.to(device)\n",
    "        \n",
    "        xx = xx.unsqueeze(1)\n",
    "        yy = yy.unsqueeze(1)\n",
    "        \n",
    "        # print(xx.shape, yy.shape)\n",
    "        loss = 0\n",
    "        ims = []\n",
    "        for y in yy.transpose(0,1):\n",
    "            im = model(xx)\n",
    "            im = im.squeeze(1)\n",
    "            # print('im: ', im.shape)\n",
    "            # print('y: ', y.shape)\n",
    "            im = im.unsqueeze(1)\n",
    "            xx = torch.cat([xx[:, 2:], im], 1)\n",
    "            loss += loss_function(im, y)\n",
    "        train_mse.append(loss.item()/yy.shape[1]) \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    train_mse = round(np.sqrt(np.mean(train_mse)),5)\n",
    "    return train_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db31c3a-69ab-42d6-86ab-3699578f5ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Eval epoch function '''\n",
    "\n",
    "def eval_epoch(valid_loader, model, loss_function):\n",
    "    valid_mse = []\n",
    "    preds = []\n",
    "    trues = []\n",
    "    with torch.no_grad():\n",
    "        for xx, yy in valid_loader:\n",
    "            xx = xx.to(device)\n",
    "            yy = yy.to(device)\n",
    "\n",
    "            xx = xx.unsqueeze(1)\n",
    "            yy = yy.unsqueeze(1)\n",
    "\n",
    "            loss = 0\n",
    "            ims = []\n",
    "            for y in yy.transpose(0, 1):\n",
    "                # y = y.unsqueeze(1)\n",
    "                im = model(xx)\n",
    "                im = im.squeeze(1)\n",
    "                im = im.unsqueeze(1)\n",
    "                xx = torch.cat([xx[:, 2:], im], 1)\n",
    "                loss += loss_function(im, y)\n",
    "                ims.append(im.unsqueeze(1).cpu().data.numpy())\n",
    "                \n",
    "            ims = np.concatenate(ims, axis = 1)\n",
    "            preds.append(ims)\n",
    "            trues.append(yy.cpu().data.numpy())\n",
    "            valid_mse.append(loss.item()/yy.shape[1])\n",
    "        preds = np.concatenate(preds, axis = 0)  \n",
    "        trues = np.concatenate(trues, axis = 0)  \n",
    "        valid_mse = round(np.sqrt(np.mean(valid_mse)), 5)\n",
    "    return valid_mse, preds, trues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86a9368-058c-4d84-ada2-239b332153cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Test epoch function '''\n",
    "\n",
    "def test_epoch(valid_loader, model, loss_function):\n",
    "    valid_mse = []\n",
    "    preds = []\n",
    "    trues = []\n",
    "    with torch.no_grad():\n",
    "        loss_curve = []\n",
    "        for xx, yy in valid_loader:\n",
    "            xx = xx.to(device)\n",
    "            yy = yy.to(device)\n",
    "\n",
    "            xx = xx.unsqueeze(1)\n",
    "            yy = yy.unsqueeze(1)\n",
    "\n",
    "            loss = 0\n",
    "            ims = []\n",
    "            \n",
    "            for y in yy.transpose(0, 1):\n",
    "                # y = y.unsqueeze(1)\n",
    "                im = model(xx)\n",
    "                im = im.squeeze(1)\n",
    "                im = im.unsqueeze(1)\n",
    "                xx = torch.cat([xx[:, 2:], im], 1)\n",
    "                mse = loss_function(im, y)\n",
    "                loss += mse\n",
    "                loss_curve.append(mse.item())\n",
    "                ims.append(im.unsqueeze(1).cpu().data.numpy())\n",
    "           \n",
    "            ims = np.concatenate(ims, axis = 1)\n",
    "            preds.append(ims)\n",
    "            trues.append(yy.cpu().data.numpy())\n",
    "            valid_mse.append(loss.item()/yy.shape[1])\n",
    "            \n",
    "        loss_curve = np.array(loss_curve).reshape(-1,yy.shape[1])\n",
    "        preds = np.concatenate(preds, axis = 0)  \n",
    "        trues = np.concatenate(trues, axis = 0)  \n",
    "        valid_mse = np.mean(valid_mse)\n",
    "        loss_curve = np.sqrt(np.mean(loss_curve, axis = 0))\n",
    "    return valid_mse, preds, trues, loss_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799b066e-9205-442d-99b0-9064a65812b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mse = []\n",
    "valid_mse = []\n",
    "test_mse = []\n",
    "times = []\n",
    "\n",
    "min_mse = 100\n",
    "\n",
    "n_epochs = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fb92d1-429c-4c1a-b4ce-e799dfeec839",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in tqdm(range(n_epochs)):\n",
    "\n",
    "    print('EPOCH: ', i+1)\n",
    "\n",
    "    start = time.time()\n",
    "    optimizer.step()\n",
    "\n",
    "    model.train()\n",
    "    print('Model trained')\n",
    "\n",
    "    train_mse.append(train_epoch(train_loader, model, optimizer, loss_fun))\n",
    "    model.eval()\n",
    "    mse, _, _ = eval_epoch(valid_loader, model, loss_fun)\n",
    "    valid_mse.append(mse)\n",
    "    \n",
    "    if valid_mse[-1] < min_mse:\n",
    "        min_mse = valid_mse[-1] \n",
    "        best_model = model\n",
    "\n",
    "    end = time.time()\n",
    "    \n",
    "    times.append(end-start)\n",
    "    \n",
    "    # Early Stopping but train at least for 50 epochs\n",
    "    # if (len(train_mse) > 50 and np.mean(valid_mse[-5:]) >= np.mean(valid_mse[-10:-5])):\n",
    "    #         break\n",
    "            \n",
    "    print('TRAIN MSE: ', train_mse[-1])\n",
    "    print('VALID MSE: ', valid_mse[-1])\n",
    "    print('TIME: ', end - start)\n",
    "    print('----------------------------------')\n",
    "\n",
    "test_mse, preds, trues, loss_curve = test_epoch(test_loader, best_model, loss_fun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ccd0bf-db49-4144-8f48-23de47cfd7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Plot Loss Curves '''\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(train_mse, label='Train')\n",
    "plt.plot(valid_mse, label='Valid')\n",
    "plt.xlabel('Epoch #')\n",
    "plt.ylabel('MSE')\n",
    "plt.title('MSE')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ab976d-b5a2-4955-b8bb-9cbf72e72387",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
