{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11656eb2-1136-41d5-873d-165d2d250fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Imports '''\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils import data\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits import mplot3d\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils import data\n",
    "import itertools\n",
    "import re\n",
    "import random\n",
    "import time\n",
    "from torch.autograd import Variable\n",
    "import math\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from torch.autograd import Variable\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c4403c-f575-4916-b1c3-84678c439106",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Train epoch function '''\n",
    "\n",
    "def train_epoch(train_loader, model, optimizer, loss_function):\n",
    "    train_mse = []\n",
    "\n",
    "    for xx, yy in train_loader:\n",
    "        \n",
    "        xx = xx.to(device)\n",
    "        yy = yy.to(device)\n",
    "\n",
    "        xx = xx.unsqueeze(1)\n",
    "        yy = yy.unsqueeze(1)\n",
    "\n",
    "        loss = 0\n",
    "        ims = []\n",
    "\n",
    "        for y in yy.transpose(0, 1):\n",
    "            y = y.unsqueeze(1)\n",
    "            im = model(xx)\n",
    "            # print(im.shape)\n",
    "            xx = torch.cat([xx[:, 2:], im], 1)\n",
    "            loss += loss_function(im, y)\n",
    "        \n",
    "        train_mse.append(loss.item()/yy.shape[1]) \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    train_mse = round(np.sqrt(np.mean(train_mse)),5)\n",
    "    return train_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7dda66c-7015-4fa3-9ebd-4013bd58f8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Eval epoch function '''\n",
    "\n",
    "def eval_epoch(valid_loader, model, loss_function):\n",
    "    valid_mse = []\n",
    "    preds = []\n",
    "    trues = []\n",
    "    with torch.no_grad():\n",
    "        for xx, yy in valid_loader:\n",
    "            xx = xx.to(device)\n",
    "            yy = yy.to(device)\n",
    "\n",
    "            xx = xx.unsqueeze(1)\n",
    "            yy = yy.unsqueeze(1)\n",
    "\n",
    "            loss = 0\n",
    "            ims = []\n",
    "            for y in yy.transpose(0, 1):\n",
    "                y = y.unsqueeze(1)\n",
    "                im = model(xx)\n",
    "                xx = torch.cat([xx[:, 2:], im], 1)\n",
    "                loss += loss_function(im, y)\n",
    "                ims.append(im.unsqueeze(1).cpu().data.numpy())\n",
    "                \n",
    "            ims = np.concatenate(ims, axis = 1)\n",
    "            preds.append(ims)\n",
    "            trues.append(yy.cpu().data.numpy())\n",
    "            valid_mse.append(loss.item()/yy.shape[1])\n",
    "        preds = np.concatenate(preds, axis = 0)  \n",
    "        trues = np.concatenate(trues, axis = 0)  \n",
    "        valid_mse = round(np.sqrt(np.mean(valid_mse)), 5)\n",
    "    return valid_mse, preds, trues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c48d7b-00dd-4e95-b0b4-9924aea8d68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Test epoch function '''\n",
    "\n",
    "def test_epoch(valid_loader, model, loss_function):\n",
    "    valid_mse = []\n",
    "    preds = []\n",
    "    trues = []\n",
    "    with torch.no_grad():\n",
    "        loss_curve = []\n",
    "        for xx, yy in valid_loader:\n",
    "            xx = xx.to(device)\n",
    "            yy = yy.to(device)\n",
    "\n",
    "            xx = xx.unsqueeze(1)\n",
    "            yy = yy.unsqueeze(1)\n",
    "\n",
    "            loss = 0\n",
    "            ims = []\n",
    "            \n",
    "            for y in yy.transpose(0, 1):\n",
    "                y = y.unsqueeze(1)\n",
    "                im = model(xx)\n",
    "                xx = torch.cat([xx[:, 2:], im], 1)\n",
    "                mse = loss_function(im, y)\n",
    "                loss += mse\n",
    "                loss_curve.append(mse.item())\n",
    "                ims.append(im.unsqueeze(1).cpu().data.numpy())\n",
    "           \n",
    "            ims = np.concatenate(ims, axis = 1)\n",
    "            preds.append(ims)\n",
    "            trues.append(yy.cpu().data.numpy())\n",
    "            valid_mse.append(loss.item()/yy.shape[1])\n",
    "            \n",
    "        loss_curve = np.array(loss_curve).reshape(-1,yy.shape[1])\n",
    "        preds = np.concatenate(preds, axis = 0)  \n",
    "        trues = np.concatenate(trues, axis = 0)  \n",
    "        valid_mse = np.mean(valid_mse)\n",
    "        loss_curve = np.sqrt(np.mean(loss_curve, axis = 0))\n",
    "    return valid_mse, preds, trues, loss_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5772397-9511-4f85-9240-b457dca36651",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Data Loader '''\n",
    "\n",
    "class Dataset(data.Dataset):\n",
    "    def __init__(self, indices, direc):\n",
    "        self.list_IDs = indices\n",
    "        self.direc = direc\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.list_IDs)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        ID = self.list_IDs[index]\n",
    "        \n",
    "        x = torch.load(self.direc + 'h_' + str(ID) + \".pt\")\n",
    "        y = torch.load(self.direc + 'T_' + str(ID) + \".pt\")\n",
    "        \n",
    "        return x.float(), y.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a648eb-d7f7-433e-b48a-3560c938b538",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Dataset Parameters '''\n",
    "\n",
    "batch_size = 8\n",
    "train_direc = \"../simulated_data_reg/\"\n",
    "valid_direc = \"../simulated_data_reg/\"\n",
    "test_direc = \"../simulated_data_reg/\"\n",
    "train_indices = list(range(0, 300))\n",
    "valid_indices = list(range(300, 370))\n",
    "test_indices = list(range(370, 465))\n",
    "# train_indices = list(range(0, 200))\n",
    "# valid_indices = list(range(200, 250))\n",
    "# test_indices = list(range(250, 270))\n",
    "\n",
    "''' Load Data '''\n",
    "\n",
    "train_set = Dataset(train_indices, train_direc)\n",
    "valid_set = Dataset(valid_indices, valid_direc)\n",
    "test_set = Dataset(test_indices, test_direc)\n",
    "\n",
    "train_loader = data.DataLoader(train_set, batch_size = batch_size, shuffle = True, num_workers = 8)\n",
    "valid_loader = data.DataLoader(valid_set, batch_size = batch_size, shuffle = True, num_workers = 8)\n",
    "test_loader = data.DataLoader(test_set, batch_size = batch_size, shuffle = False, num_workers = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f289c20b-690f-46bb-9d5a-66e21ac4df51",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Model Hyperparameters '''\n",
    "\n",
    "n_epochs = 60\n",
    "learning_rate = 0.001\n",
    "lr_decay = 0.9\n",
    "\n",
    "min_mse = 100\n",
    "train_mse = []\n",
    "valid_mse = []\n",
    "test_mse = []\n",
    "times = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e163e12d-1c9e-4a4f-a1b5-806f2f9df5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=2, stride=1, padding = 1),\n",
    "            nn.ReLU())\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, kernel_size=2, stride=1),\n",
    "            nn.ReLU())\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=2, stride=1, padding = 1),\n",
    "            nn.ReLU())\n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=2, stride=1),\n",
    "            nn.ReLU())\n",
    "        self.layer5 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, kernel_size=2, stride=1),\n",
    "            nn.ReLU())\n",
    "        self.layer6 = nn.Sequential(\n",
    "            nn.Conv2d(256, 512, kernel_size=2, stride=1, padding = 1),\n",
    "            nn.ReLU())\n",
    "        self.layer7 = nn.Sequential(\n",
    "            nn.Conv2d(512, 512, kernel_size=2, stride=1, padding = 1),\n",
    "            nn.ReLU())\n",
    "        self.layer8 = nn.Sequential(\n",
    "            nn.Conv2d(512, 512, kernel_size=2, stride=1, padding = 1),\n",
    "            nn.ReLU())\n",
    "        self.layer9 = nn.Sequential(\n",
    "            nn.Conv2d(512, 256, kernel_size=2, stride=1, padding = 1),\n",
    "            nn.ReLU())\n",
    "        self.layer10 = nn.Sequential(\n",
    "            nn.Conv2d(256, 128, kernel_size=2, stride=1, padding = 1),\n",
    "            nn.ReLU())\n",
    "        self.layer11 = nn.Sequential(\n",
    "            nn.Conv2d(128, 64, kernel_size=2, stride=1),\n",
    "            nn.ReLU())\n",
    "        self.layer12 = nn.Sequential(\n",
    "            nn.Conv2d(64, 32, kernel_size=2, stride=1),\n",
    "            nn.ReLU())\n",
    "        self.layer13 = nn.Sequential(\n",
    "            nn.Conv2d(32, 16, kernel_size=2, stride=1),\n",
    "            nn.ReLU())\n",
    "        self.layer14 = nn.Sequential(\n",
    "            nn.Conv2d(16, 1, kernel_size=2, stride=1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.layer5(out)\n",
    "        out = self.layer6(out)\n",
    "        out = self.layer7(out)\n",
    "        out = self.layer8(out)\n",
    "        out = self.layer9(out)\n",
    "        out = self.layer10(out)\n",
    "        out = self.layer11(out)\n",
    "        out = self.layer12(out)\n",
    "        out = self.layer13(out)\n",
    "        out = self.layer14(out)\n",
    "        return out  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a58ca0d-0e7a-45ff-ab15-2645ea091983",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN().to(device) \n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3e7308-b136-47a7-9a3f-65574bc00536",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Parameters: ', sum(p.numel() for p in model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b781e7f-80cf-4d8d-9b1c-64499ad34e7e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in tqdm(range(n_epochs)):\n",
    "\n",
    "    print('EPOCH: ', i+1)\n",
    "\n",
    "    start = time.time()\n",
    "    # scheduler.step()\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    train_mse.append(train_epoch(train_loader, model, optimizer, criterion))\n",
    "    model.eval()\n",
    "    mse, _, _ = eval_epoch(valid_loader, model, criterion)\n",
    "    valid_mse.append(mse)\n",
    "    \n",
    "    if valid_mse[-1] < min_mse:\n",
    "        min_mse = valid_mse[-1] \n",
    "        best_model = model\n",
    "\n",
    "    end = time.time()\n",
    "    \n",
    "    times.append(end-start)\n",
    "    \n",
    "    # Early Stopping but train at least for 50 epochs\n",
    "    # if (len(train_mse) > 50 and np.mean(valid_mse[-5:]) >= np.mean(valid_mse[-10:-5])):\n",
    "    #         break\n",
    "            \n",
    "    print('TRAIN MSE: ', train_mse[-1])\n",
    "    print('VALID MSE: ', valid_mse[-1])\n",
    "    print('TIME: ', end - start)\n",
    "    print('----------------------------------')\n",
    "\n",
    "test_mse, preds, trues, loss_curve = test_epoch(test_loader, best_model, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfb420e-db6d-454c-abde-796eb0005465",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Plot Loss Curves '''\n",
    "\n",
    "plt.plot(train_mse, label='Train')\n",
    "plt.plot(valid_mse, label='Valid')\n",
    "plt.xlabel('Epoch #')\n",
    "plt.ylabel('MSE')\n",
    "plt.title('MSE')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44757e1d-2c1f-407f-a52a-dc77476e635b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.load('../simulated_data_reg/h_0.pt')\n",
    "y = torch.load('../simulated_data_reg/T_0.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe30e14e-65a1-4068-9704-356531794446",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' EDA '''\n",
    "\n",
    "row = 100\n",
    "\n",
    "output = model(x.unsqueeze(0).unsqueeze(0).to(device))\n",
    "output = output.squeeze(0).squeeze(0)\n",
    "\n",
    "plt.hist(x[row].cpu().detach().numpy(), color = \"blue\", label=\"height\")\n",
    "plt.hist(y[row].cpu().detach().numpy(), color = \"red\", label=\"original temperature\")\n",
    "plt.hist(output[row].cpu().detach().numpy(), color = \"green\", label=\"output temperature\")\n",
    "plt.title('Row ' + str(row))    \n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4bf0c8-05a5-4852-8534-b6cb78be6802",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Visualize model output '''\n",
    "\n",
    "height = x.numpy()\n",
    "plt.imshow(height, cmap='hot', interpolation='nearest')\n",
    "plt.title('Height profile')\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "original_temperature = y.numpy()\n",
    "plt.imshow(original_temperature, cmap='hot', interpolation='nearest')\n",
    "plt.title('Original temperature profile')\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "output = model(x.unsqueeze(0).unsqueeze(0).to(device))\n",
    "output = output.squeeze(0).squeeze(0)\n",
    "output = output.cpu().detach().numpy()\n",
    "plt.imshow(output, cmap='hot', interpolation='nearest')\n",
    "plt.title('Predicted temperature profile')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef383d64-e4d5-4f60-abbf-3fcb044964c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_and_metrics_dict = {}\n",
    "model_and_metrics_dict['train_mse'] = train_mse\n",
    "model_and_metrics_dict['valid_mse'] = valid_mse\n",
    "model_and_metrics_dict['test_mse'] = test_mse\n",
    "model_and_metrics_dict['epochs'] = n_epochs\n",
    "model_and_metrics_dict['learning_rate'] = learning_rate\n",
    "model_and_metrics_dict['model'] = 'cnn'\n",
    "model_and_metrics_dict['time'] = times\n",
    "\n",
    "print(model_and_metrics_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1702c2d6-6917-4bfc-92ba-f869b29eac08",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"../trained_models/cnn_backward.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2982a5-696e-48c7-ac34-0c8e7d53d53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../metrics/cnn_backward.json', 'w') as f:\n",
    "    json.dump(model_and_metrics_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749b9dec-92e3-49d8-bfcb-253e212589eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
