{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7a80995-4c34-4973-b425-7562ab148055",
   "metadata": {},
   "source": [
    "<h2>IMPORTS</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9056f6c6-7d28-4ec9-9fa3-fcbfd9639de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import tempfile\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from __future__ import division\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from matplotlib import animation\n",
    "from IPython.display import clear_output\n",
    "import pandas as pd\n",
    "\n",
    "from PIL import Image\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878f291f-4a79-4d0c-8a98-f326a46328b8",
   "metadata": {},
   "source": [
    "<h2>SUPPORTING FUNCTIONS</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae67782b-a9e6-4fdd-94ef-6269b3064ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _save_images_to_folder(dataset, transform, path, split_name, idx, format_='.png'):\n",
    "    scales = {}\n",
    "    for el in dataset:\n",
    "        img = transform(el[0])\n",
    "        out = os.path.join(path, split_name, str(el[1]))\n",
    "        if not os.path.exists(out):\n",
    "            os.makedirs(out)\n",
    "        img_path = os.path.join(out, str(idx) + format_)\n",
    "        img.save(img_path)\n",
    "        idx += 1\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f1010c-d5ab-4ebf-a4eb-1db1eec3e6b7",
   "metadata": {},
   "source": [
    "<h2>ARGUMENTS</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74edd128-4e85-4472-a6bf-6417e8c24c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATHS\n",
    "MNIST_DIR = 'datasets/'\n",
    "MNIST_SCALE_DIR = 'datasets/'\n",
    "\n",
    "# SCALE VALUES\n",
    "min_scale = 1.0\n",
    "max_scale = 1.0\n",
    "\n",
    "scales = [1.0]\n",
    "\n",
    "# SEED VALUES\n",
    "seeds = [0]\n",
    "\n",
    "BUF_SIZE = 65536\n",
    "\n",
    "# TRAIN_VAL_TEST SIZE\n",
    "MNIST_TRAIN_SIZE = 300\n",
    "MNIST_VAL_SIZE = 70\n",
    "MNIST_TEST_SIZE = 100\n",
    "\n",
    "transform = transforms.RandomAffine(0, scale=(min_scale, max_scale))\n",
    "\n",
    "source = 'datasets/'\n",
    "dest = 'datasets/'\n",
    "\n",
    "download = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64595f5-0462-4a78-8877-e15305567e60",
   "metadata": {},
   "source": [
    "<h2>DOWNLOAD DATASET</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24a71e5-1364-4918-8c6b-ffc96291b6be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for seed in seeds:\n",
    "    \n",
    "    for min_scale in scales:\n",
    "    \n",
    "        print('Seed: ', seed)\n",
    "        print('min_scale: ', min_scale)\n",
    "\n",
    "        np.random.seed(seed)\n",
    "        random.seed(seed)\n",
    "\n",
    "        dataset_train = datasets.MNIST(root=source, train=True, download=download)\n",
    "        dataset_test = datasets.MNIST(root=source, train=False, download=download)\n",
    "        concat_dataset = ConcatDataset([dataset_train, dataset_test])\n",
    "\n",
    "        labels = [el[1] for el in concat_dataset]\n",
    "        train_val_size = MNIST_TRAIN_SIZE + MNIST_VAL_SIZE\n",
    "        train_val, test = train_test_split(concat_dataset, train_size=train_val_size,\n",
    "                                               test_size=MNIST_TEST_SIZE, stratify=labels)\n",
    "\n",
    "        labels = [el[1] for el in train_val]\n",
    "        train, val = train_test_split(train_val, train_size=MNIST_TRAIN_SIZE,\n",
    "                                          test_size=MNIST_VAL_SIZE, stratify=labels)\n",
    "\n",
    "        dataset_path = os.path.join(dest, 'MNIST_reg', \"seed_{}\".format(seed))\n",
    "        dataset_path = os.path.join(dataset_path, \"reg_{}_{}\".format(min_scale, max_scale))\n",
    "        print('OUTPUT: {}'.format(dataset_path))\n",
    "\n",
    "        idx = _save_images_to_folder(train, transform, dataset_path, 'train', 0, '.png')\n",
    "        idx = _save_images_to_folder(test, transform, dataset_path, 'test', idx, '.png')\n",
    "        idx = _save_images_to_folder(val, transform, dataset_path, 'val', idx, '.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d7d42c-a072-4858-bc5f-1e278d0de2a2",
   "metadata": {},
   "source": [
    "<h2>TFLE SIMULATIONS</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5cf33a-4857-4776-9b53-2fb0f488b938",
   "metadata": {},
   "source": [
    "<h2>SIMULATIONS FUNCTIONS</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba09f16-82c7-450e-be81-114d81340e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linspace(start, stop, n):\n",
    "    arr = []\n",
    "    h = (stop - start) / (n - 1)\n",
    "    for i in range(n):\n",
    "        arr.append(start + (h * i))\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a76fb7-12b4-4708-820e-c2fea1d560da",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Physical and temperature distribution parameters '''\n",
    "\n",
    "Lx = 10e-6\n",
    "dx = 50e-9\n",
    "h0 = 100e-9\n",
    "dt_default = 1000e-8\n",
    "dt_scaleFactor = 0.5\n",
    "\n",
    "p = 1\n",
    "mode = 1\n",
    "width = np.array(linspace((Lx/10), (Lx/4), 20))\n",
    "amp = np.array(linspace(1,50,12))\n",
    "shift = np.array(linspace(0, Lx, 10))\n",
    "T_amb = 300\n",
    "\n",
    "build_plots = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726b5ae5-879d-4dca-bb5a-af3e9c1caa26",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Material properties '''\n",
    "\n",
    "mu = 2.5e4\n",
    "B = -0.0855"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0795e8c5-a4b8-4f3f-bf2b-f50ba124ff87",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Simulation params '''\n",
    "\n",
    "num_iterations = 4000\n",
    "num_tests_to_complete = 1\n",
    "n_cell = Lx/dx\n",
    "n = int(n_cell + 1)\n",
    "\n",
    "start = 0\n",
    "xs = []\n",
    "for i in range(int(Lx/dx)):\n",
    "    xs.append(start)\n",
    "    start += dx\n",
    "xs = np.array(xs)\n",
    "\n",
    "test_count = 0\n",
    "\n",
    "i_max = len(width)\n",
    "j_max = len(amp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b65b62-6ca5-4fd5-9e64-20675b13906c",
   "metadata": {},
   "source": [
    "<h2>ARGUMENTS</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266fa2b4-c775-462f-b313-4613c4f0883d",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = 'datasets/MNIST_reg/'\n",
    "\n",
    "path_list = []\n",
    "\n",
    "for folder in os.listdir(root_dir):\n",
    "    for sub_folder in os.listdir(root_dir + folder + '/'):\n",
    "        for test_train_val_folder in os.listdir(root_dir + folder + '/' + sub_folder + '/'):\n",
    "            for number_file in os.listdir(root_dir + folder + '/' + sub_folder + '/' + test_train_val_folder + '/'):\n",
    "                for mnist_file in os.listdir(root_dir + folder + '/' + sub_folder + '/' + test_train_val_folder + '/' + number_file + '/'):\n",
    "                    # print(root_dir + folder + '/' + sub_folder + '/' + test_train_val_folder + '/' + number_file + '/' + mnist_file)\n",
    "                    path_list.append(root_dir + folder + '/' + sub_folder + '/' + test_train_val_folder + '/' + number_file + '/' + mnist_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98481e89-c4d9-494c-a504-70161d83bb8f",
   "metadata": {},
   "source": [
    "<h2>GENERATE DATASET</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11131ab3-b670-4565-9882-3edb232440f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "simulated_dataset_path = 'mnist_experiments/mnist_simulated_dataset_reg/'\n",
    "\n",
    "for path in path_list:\n",
    "    print(path)\n",
    "    index_file = path.split('/')[-1]\n",
    "    seed_value = path.split('/')[-5].split('_')[-1]\n",
    "    index_value = index_file.split('.')[0]\n",
    "    new_file_name = 'T_' + seed_value + '_' + index_file\n",
    "    new_path = simulated_dataset_path + 'png/' + new_file_name\n",
    "    print('New path: ', new_path)\n",
    "    shutil.copy(path, new_path)\n",
    "    # simulate_tfle(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7146189c-3633-4f4a-94c7-f12124b5a05d",
   "metadata": {},
   "source": [
    "<h2>PNG -> PT</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f16b120-03fe-4e47-ad67-e2e0b7983b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in os.listdir('mnist_experiments/mnist_simulated_dataset_reg/png/'):\n",
    "    new_path = 'mnist_experiments/mnist_simulated_dataset_reg/png/' + i\n",
    "    \n",
    "    if('.png' in i):\n",
    "        image = Image.open(new_path)\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Grayscale(),\n",
    "            transforms.Resize(200),\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "        \n",
    "        img_tensor = transform(image)\n",
    "        # print(i.split('.')[0] + '.pt')\n",
    "        file_name = 'mnist_experiments/mnist_simulated_dataset_reg/pt/' + i.split('.')[0] + '.pt'\n",
    "        # print(file_name)\n",
    "        torch.save(img_tensor, file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54f5850-92d1-4a63-94fb-d2b15702538a",
   "metadata": {},
   "source": [
    "<h2>CARRY OUT TFLE SIMULATIONS</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf5f422-8bfc-4884-8485-d7b25d29655d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_tensors_resized = []\n",
    "\n",
    "tensor_300 = torch.empty(1, 200, 200).fill_(300.)\n",
    "\n",
    "for tensor_file in os.listdir('mnist_experiments/mnist_simulated_dataset_reg/pt/'):\n",
    "    \n",
    "    t_tensor = torch.load('mnist_experiments/mnist_simulated_dataset_reg/pt/' + tensor_file)\n",
    "    \n",
    "    t_tensor = t_tensor * 30\n",
    "    \n",
    "    t_tensor = t_tensor + tensor_300\n",
    "    \n",
    "    mnist_tensors_resized.append(t_tensor)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d197cfc6-770c-436b-9769-1b74d23f10df",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_tensors_resized = mnist_tensors_resized[:470]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52d4144-d00f-4d70-854c-7d831a2346f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_numpy_arrays = []\n",
    "\n",
    "for tensor in mnist_tensors_resized:\n",
    "    mnist_numpy_arrays.append(tensor.cpu().detach().numpy())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee8641c-9f85-4516-9cfb-64eeab7ddddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64c48ce-5aed-421e-a88e-abdea6f4d459",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for mnist in tqdm(mnist_numpy_arrays):\n",
    "    \n",
    "    dt = dt_default\n",
    "    test_count = i\n",
    "    \n",
    "    # t, amp_avg, amp1, amp2, w1, w2, shift1, shift2 = initialize_temperature_array(amp, width, shift, xs, T_amb, Lx, n)\n",
    "    # t = initialize_temperature_array(amp, width, shift, xs, T_amb, Lx, n)\n",
    "    \n",
    "    mnist = mnist[0][:200, :200]\n",
    "    \n",
    "    # T = np.zeros((200, 200))\n",
    "    # for j in range(200):\n",
    "    #     T[j] = np.roll(t, -j)\n",
    "        \n",
    "    # T = np.subtract(T + mnist, 300)\n",
    "\n",
    "    T = mnist\n",
    "    \n",
    "    T_x1 = np.roll(T, 1, axis = 1)\n",
    "    Tx1 = np.roll(T, -1, axis = 1)\n",
    "    T_y1 = np.roll(T, 1, axis = 0)\n",
    "    Ty1 = np.roll(T, -1, axis = 0)\n",
    "    \n",
    "    dtdx = ((-0.5 * T_x1) + (0.5 * Tx1))/dx;\n",
    "    dy = dx\n",
    "    dtdy = ((-0.5 * T_y1) + (0.5 * Ty1))/dy;\n",
    "    \n",
    "    gam = 31.53 - (0.0855*T)\n",
    "    \n",
    "    gam_x1 = np.roll(gam, 1, axis = 1)\n",
    "    gamx1 = np.roll(gam, -1, axis = 1)\n",
    "    gam_y1 = np.roll(gam, 1, axis = 0)\n",
    "    gamy1 = np.roll(gam, -1, axis = 0)\n",
    "    \n",
    "    # if(build_plots):\n",
    "    #     plt.imshow(T, cmap = 'hot')\n",
    "    \n",
    "    for tr in range(1):\n",
    "        if(tr == 0):\n",
    "            dt = dt * dt_scaleFactor\n",
    "        \n",
    "        fluxX = np.zeros((200, 200))\n",
    "        fluxY = np.zeros((200, 200))\n",
    "        dfluxXdx = np.zeros((200, 200))\n",
    "        dfluxYdy = np.zeros((200, 200))\n",
    "        dhdt_max = 0\n",
    "        h = h0 * np.ones((200, 200))\n",
    "        status = 'incomplete'\n",
    "        \n",
    "        for r in range(num_iterations):\n",
    "        # for r in range(10):\n",
    "            # print('Enter num_iterations: ', r)\n",
    "            \n",
    "            h_x1 = np.roll(h, 1, axis = 1)\n",
    "            hx1 = np.roll(h, -1, axis = 1)\n",
    "            h_y1 = np.roll(h, 1, axis = 0)\n",
    "            hy1 = np.roll(h, -1, axis = 0)\n",
    "            \n",
    "            h_x2 = np.roll(h, 2, axis = 1)\n",
    "            hx2 = np.roll(h, -2, axis = 1)\n",
    "            h_y2 = np.roll(h, 2, axis = 0)\n",
    "            hy2 = np.roll(h, -2, axis = 0)\n",
    "            \n",
    "            fluxX_x1 = np.roll(fluxX, 1, axis = 1)\n",
    "            fluxXx1 = np.roll(fluxX, -1, axis = 1)\n",
    "            dfluxXdx_x1 = np.roll(dfluxXdx, 1, axis = 1)\n",
    "            dfluxXdxx1 = np.roll(dfluxXdx, -1, axis = 1)\n",
    "            \n",
    "            fluxY_y1 = np.roll(fluxY, 1, axis = 0)\n",
    "            fluxYy1 = np.roll(fluxY, -1, axis = 0)\n",
    "            dfluxY_y1 = np.roll(dfluxYdy, 1, axis = 0)\n",
    "            dfluxYy1 = np.roll(dfluxYdy, -1, axis = 0)\n",
    "            \n",
    "            dhdx2 = (h_x1 - (2 * h) + hx1)/(dx*dx)\n",
    "            dhdx3 = (((-0.5 * h_x2) + h_x1 - hx1 + (0.5 * hx2))/(dx*dx*dx))\n",
    "            \n",
    "            dhdy2 = (h_y1 - (2 * h) + hy1)/(dy*dy)\n",
    "            dhdy3 = (((-0.5 * h_y2) + h_y1 - hy1 + (0.5 * hy2))/(dy*dy*dy))\n",
    "            \n",
    "            deltah = dhdx2 + dhdy2\n",
    "            \n",
    "            deltahx1 = np.roll(deltah, -1, axis = 1)\n",
    "            deltahy1 = np.roll(deltah, -1, axis = 0)\n",
    "            deltah_x1 = np.roll(deltah, 1, axis = 1)\n",
    "            deltah_y1 = np.roll(deltah, 1, axis = 0)\n",
    "            \n",
    "            ddeltahdx = ((-0.5*deltah_x1) + (0.5*deltahx1))/dx\n",
    "            ddeltahdy = ((-0.5*deltah_y1) + (0.5*deltahy1))/dy\n",
    "            \n",
    "            fluxX = np.multiply(((np.square(h)*B)/(2*mu)), dtdx) + np.multiply(np.multiply((np.power(h, 3)/(3*mu)), dtdx), deltah) + np.multiply(np.multiply((np.power(h, 3)/(3*mu)), gam), ddeltahdx)\n",
    "            fluxY = np.multiply(((np.square(h)*B)/(2*mu)), dtdy) + np.multiply(np.multiply((np.power(h, 3)/(3*mu)), dtdy), deltah) + np.multiply(np.multiply((np.power(h, 3)/(3*mu)), gam), ddeltahdy)\n",
    "            \n",
    "            dfluxXdx = ((-0.5 * fluxX_x1) + (0.5 * fluxXx1))/dx\n",
    "            dflux = ((-0.5 * fluxY_y1) + (0.5 * fluxYy1))/dy\n",
    "            \n",
    "            dhdt = (-1 * dfluxXdx) + (-1 * dfluxYdy)\n",
    "            \n",
    "            if(dhdt_max > 10000000):\n",
    "                status = 'failed'\n",
    "                print('Failed')\n",
    "                break\n",
    "                \n",
    "            if(dhdt.flat[np.abs(dhdt).argmax()]   > dhdt_max):\n",
    "                dhdt_max = dhdt.flat[np.abs(dhdt).argmax()]\n",
    "                # print('dhdt_max: ', dhdt_max)\n",
    "                \n",
    "            # if(dhdt.flat[np.abs(dhdt).argmax()] < (dhdt_max * 0.01)):\n",
    "            #     print('Falied 2')\n",
    "            #     break\n",
    "                \n",
    "            h = h + (dhdt * dt)\n",
    "            \n",
    "            for m in range(len(h)):\n",
    "                for n in range(len(h[m])):\n",
    "                    if(h[m][n]<0):\n",
    "                        h[m][n] = 0\n",
    "                        \n",
    "#             if True in np.isnan(fluxX):\n",
    "#                 print('NaN value found in iteration: ', r)\n",
    "#                 break\n",
    "                        \n",
    "            if(build_plots and str(r)[-1] == '0'):\n",
    "                plt.imshow(h, cmap = 'hot')\n",
    "                plt.title('Height map Iteration: ' + str(r))\n",
    "                plt.colorbar()\n",
    "                plt.show()\n",
    "                clear_output(wait = True)\n",
    "\n",
    "    # Write T data    \n",
    "    t_filename = 'mnist_experiments/temp/T_' + str(file_count) + '.csv'\n",
    "    np.savetxt(t_filename, T, delimiter = \",\")    \n",
    "    \n",
    "    # Write h data\n",
    "    h_filename = 'mnist_experiments/temp/h_' + str(file_count) + '.csv'\n",
    "    np.savetxt(h_filename, h, delimiter = \",\") \n",
    "    \n",
    "    print('File ', file_count, ' done!')\n",
    "    print('Iterations done: ', r)\n",
    "    \n",
    "    file_count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a728286f-fa4f-42b2-9f1e-e66489a752a6",
   "metadata": {},
   "source": [
    "<h2>CSV -> PT</h2>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a267a615-8ceb-4586-9914-df0105e1032f",
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature_files = []\n",
    "height_files = []\n",
    "\n",
    "for i in range(470):\n",
    "    if(i not in indexes):\n",
    "        temperature_files.append('mnist_experiments/temp/T_' + str(i) + '.csv')\n",
    "        height_files.append('mnist_experiments/temp/h_' + str(i) + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4c293d-fb61-42cb-8d60-b5b9d89aaabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature_data = []\n",
    "height_data = []\n",
    "\n",
    "for temperature_file in tqdm(temperature_files):\n",
    "    data = pd.read_csv(temperature_file, header = None)\n",
    "    temperature_data.append(data)\n",
    "    \n",
    "for height_file in tqdm(height_files):\n",
    "    data = pd.read_csv(height_file, header = None)\n",
    "    height_data.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b52d6d-3ac7-4eea-909b-960ad5359c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature_tensor = torch.tensor(np.array(temperature_data))\n",
    "height_tensor = torch.tensor(np.array(height_data))\n",
    "\n",
    "torch.save(temperature_tensor, 'mnist_experiments/temp/temperature_tensor.pt')\n",
    "torch.save(height_tensor, 'mnist_experiments/temp/height_tensor.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9e7798-ecaa-43aa-9cd1-ff2241b82f3e",
   "metadata": {},
   "source": [
    "<h2>READ TENSORS</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbc5928-75d6-425a-a019-30a60fc61963",
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature_tensor = torch.load('mnist_experiments/temp/temperature_tensor.pt')\n",
    "height_tensor = torch.load('mnist_experiments/temp/height_tensor.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5275bac-928b-496f-a508-4f6ff54e5483",
   "metadata": {},
   "source": [
    "<h2>EXAMPLE VISUALIZATIONS</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44af5f61-7a1e-4337-9ca0-d860b8f93a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 201\n",
    "\n",
    "# plt.imshow(temperature_tensor[index], cmap='hot', interpolation='nearest')\n",
    "# plt.title('Temperature Profile')\n",
    "# plt.axis('off')\n",
    "# clb = plt.colorbar()\n",
    "# clb.ax.tick_params(labelsize=8) \n",
    "# clb.ax.set_title('Temperature in degree celcius',fontsize=8)\n",
    "# plt.show()\n",
    "# plt.savefig('mnist_experiments/images/temperature-5.png')\n",
    "plt.imshow(height_tensor[index], cmap='hot', interpolation='nearest')\n",
    "plt.title('Simulated Height Profile')\n",
    "plt.axis('off')\n",
    "clb = plt.colorbar()\n",
    "clb.ax.tick_params(labelsize=8) \n",
    "clb.ax.set_title('Height in nanometers',fontsize=8)\n",
    "# plt.show()\n",
    "plt.savefig('mnist_experiments/images/height-5.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca28fcb4-127e-4cab-9c44-8a459f70b99c",
   "metadata": {},
   "source": [
    "<h2>NORMALIZATION</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f095d4a0-0b47-45b5-9242-202c950162ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(height_tensor)):\n",
    "    height_tensor[i] = torch.mul(height_tensor[i], 1000000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c3ba19-b0f1-46a6-be8e-a2c71eb49af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = []\n",
    "for i in range(len(height_tensor)):\n",
    "    mean = height_tensor[i].mean()\n",
    "    # print(mean.numpy())\n",
    "    if(mean.numpy()>110):\n",
    "        indexes.append(i)\n",
    "    elif(mean.numpy()>80):\n",
    "        continue\n",
    "    else:\n",
    "        indexes.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540165b6-12c0-40e3-a68d-adde30d883b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3142f62e-c195-4320-afce-1cec0be84fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_mean = temperature_tensor.mean()\n",
    "print('t_mean: ', t_mean)\n",
    "t_std = temperature_tensor.std()\n",
    "print(t_std)\n",
    "normalized_t_tensor = ((temperature_tensor - t_mean)/t_std).float()\n",
    "\n",
    "h_mean = height_tensor.mean()\n",
    "print(h_mean)\n",
    "h_std = height_tensor.std()\n",
    "print(h_std)\n",
    "normalized_h_tensor = ((height_tensor - h_mean)/h_std).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cef085-01db-4421-b8b0-bf691a861628",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(normalized_t_tensor, 'mnist_experiments/temp/normalized_temperature_tensor.pt')\n",
    "torch.save(normalized_h_tensor, 'mnist_experiments/temp/normalized_height_tensor.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617f08cb-5f58-4cea-88c1-36f974376e87",
   "metadata": {},
   "source": [
    "<h2>INDIVIDUAL CSV FILES TO PT</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afb76a9-df8d-4840-8e50-9ce9977c922c",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "\n",
    "for tensor in tqdm(normalized_t_tensor):\n",
    "    path = 'mnist_experiments/simulated_data_reg/T_' + str(count) + '.pt'\n",
    "    torch.save(tensor, path)\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6c7f7a-a4a9-44af-a12b-348f6a8b9af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "\n",
    "for tensor in tqdm(normalized_h_tensor):\n",
    "    path = 'mnist_experiments/simulated_data_reg/h_' + str(count) + '.pt'\n",
    "    torch.save(tensor, path)\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b36c803-b38a-42aa-9f54-29c5620cde66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
