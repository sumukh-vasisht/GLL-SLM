{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ca20c50-07bb-4aa1-892e-9e8c61b90c10",
   "metadata": {},
   "source": [
    "<h2>IMPORTS</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f7ea0a-4d09-47a4-98c6-fec1ba354fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import tempfile\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from __future__ import division\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from matplotlib import animation\n",
    "from IPython.display import clear_output\n",
    "import pandas as pd\n",
    "\n",
    "from PIL import Image\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900f43db-d5cb-4b49-a6c1-c4f79017dddf",
   "metadata": {},
   "source": [
    "<h2>SIMULATIONS FUNCTIONS</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d332761f-ca34-452d-b521-89076734ff7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linspace(start, stop, n):\n",
    "    arr = []\n",
    "    h = (stop - start) / (n - 1)\n",
    "    for i in range(n):\n",
    "        arr.append(start + (h * i))\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc48ee0-b3ca-4806-8227-3370229eac57",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Physical and temperature distribution parameters '''\n",
    "\n",
    "Lx = 10e-6\n",
    "dx = 50e-9\n",
    "h0 = 100e-9\n",
    "dt_default = 1000e-8\n",
    "dt_scaleFactor = 0.5\n",
    "\n",
    "p = 1\n",
    "mode = 1\n",
    "width = np.array(linspace((Lx/10), (Lx/4), 20))\n",
    "amp = np.array(linspace(1,50,12))\n",
    "shift = np.array(linspace(0, Lx, 10))\n",
    "T_amb = 300\n",
    "\n",
    "build_plots = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3827c5f-35fb-4a89-9247-2747e041d805",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Material properties '''\n",
    "\n",
    "mu = 2.5e4\n",
    "B = -0.0855"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a88e83-fe7c-47e7-a595-5f091bf11eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Simulation params '''\n",
    "\n",
    "num_iterations = 4000\n",
    "num_tests_to_complete = 1\n",
    "n_cell = Lx/dx\n",
    "n = int(n_cell + 1)\n",
    "\n",
    "start = 0\n",
    "xs = []\n",
    "for i in range(int(Lx/dx)):\n",
    "    xs.append(start)\n",
    "    start += dx\n",
    "xs = np.array(xs)\n",
    "\n",
    "test_count = 0\n",
    "\n",
    "i_max = len(width)\n",
    "j_max = len(amp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ba69c4-f5d4-4a54-98ff-c4266b4ca32a",
   "metadata": {},
   "source": [
    "<h2>ARGUMENTS</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c8b08c-8e19-4570-8bc9-1d256c237ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = 'datasets/MNIST_scale/'\n",
    "\n",
    "path_list = []\n",
    "\n",
    "for folder in os.listdir(root_dir):\n",
    "    for sub_folder in os.listdir(root_dir + folder + '/'):\n",
    "        for test_train_val_folder in os.listdir(root_dir + folder + '/' + sub_folder + '/'):\n",
    "            for number_file in os.listdir(root_dir + folder + '/' + sub_folder + '/' + test_train_val_folder + '/'):\n",
    "                for mnist_file in os.listdir(root_dir + folder + '/' + sub_folder + '/' + test_train_val_folder + '/' + number_file + '/'):\n",
    "                    # print(root_dir + folder + '/' + sub_folder + '/' + test_train_val_folder + '/' + number_file + '/' + mnist_file)\n",
    "                    path_list.append(root_dir + folder + '/' + sub_folder + '/' + test_train_val_folder + '/' + number_file + '/' + mnist_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845501ea-844a-450c-9f45-a90deba2461d",
   "metadata": {},
   "source": [
    "<h2>GENERATE DATASET</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7207b4e9-0bcc-4008-b77a-d8a1b585c932",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "simulated_dataset_path = 'mnist_simulated_dataset/'\n",
    "\n",
    "for path in path_list:\n",
    "    print(path)\n",
    "    index_file = path.split('/')[-1]\n",
    "    seed_value = path.split('/')[-5].split('_')[-1]\n",
    "    index_value = index_file.split('.')[0]\n",
    "    new_file_name = 'T_' + seed_value + '_' + index_file\n",
    "    new_path = simulated_dataset_path + 'png/' + new_file_name\n",
    "    print('New path: ', new_path)\n",
    "    shutil.copy(path, new_path)\n",
    "    # simulate_tfle(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e70a1ba-2241-4160-883f-cb1dfd149a06",
   "metadata": {},
   "source": [
    "<h2>PNG -> PT</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0d8d86-30c5-4435-a423-76baf659eebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in os.listdir('mnist_simulated_dataset/png/'):\n",
    "    new_path = 'mnist_simulated_dataset/png/' + i\n",
    "    \n",
    "    if('.png' in i):\n",
    "        image = Image.open(new_path)\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Grayscale(),\n",
    "            transforms.Resize(200),\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "        \n",
    "        img_tensor = transform(image)\n",
    "        # print(i.split('.')[0] + '.pt')\n",
    "        file_name = 'mnist_simulated_dataset/pt/' + i.split('.')[0] + '.pt'\n",
    "        # print(file_name)\n",
    "        torch.save(img_tensor, file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7376667f-a398-4538-93a3-1bf4fb72e6b9",
   "metadata": {},
   "source": [
    "<h2>CARRY OUT TFLE SIMULATIONS</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9f5919-3be4-4bb1-8098-ab9e76f0eb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_tensors_resized = []\n",
    "\n",
    "tensor_300 = torch.empty(1, 200, 200).fill_(300.)\n",
    "\n",
    "for tensor_file in os.listdir('mnist_simulated_dataset/pt/'):\n",
    "    \n",
    "    t_tensor = torch.load('mnist_simulated_dataset/pt/' + tensor_file)\n",
    "    \n",
    "    t_tensor = t_tensor * 30\n",
    "    \n",
    "    t_tensor = t_tensor + tensor_300\n",
    "    \n",
    "    mnist_tensors_resized.append(t_tensor)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5d5a98-7f91-4ccb-9a37-affc00f23216",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_tensors_resized = mnist_tensors_resized[:400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c078ee-0de3-4948-9511-b51c740ac54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_numpy_arrays = []\n",
    "\n",
    "for tensor in mnist_tensors_resized:\n",
    "    mnist_numpy_arrays.append(tensor.cpu().detach().numpy())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e822079-c54a-4d61-be66-9bad5e864103",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ffa0e95-4a07-47a8-a064-9d5f12e2ab6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for mnist in tqdm(mnist_numpy_arrays):\n",
    "    \n",
    "    dt = dt_default\n",
    "    test_count = i\n",
    "    \n",
    "    # t, amp_avg, amp1, amp2, w1, w2, shift1, shift2 = initialize_temperature_array(amp, width, shift, xs, T_amb, Lx, n)\n",
    "    # t = initialize_temperature_array(amp, width, shift, xs, T_amb, Lx, n)\n",
    "    \n",
    "    mnist = mnist[0][:200, :200]\n",
    "    \n",
    "    # T = np.zeros((200, 200))\n",
    "    # for j in range(200):\n",
    "    #     T[j] = np.roll(t, -j)\n",
    "        \n",
    "    # T = np.subtract(T + mnist, 300)\n",
    "\n",
    "    T = mnist\n",
    "    \n",
    "    T_x1 = np.roll(T, 1, axis = 1)\n",
    "    Tx1 = np.roll(T, -1, axis = 1)\n",
    "    T_y1 = np.roll(T, 1, axis = 0)\n",
    "    Ty1 = np.roll(T, -1, axis = 0)\n",
    "    \n",
    "    dtdx = ((-0.5 * T_x1) + (0.5 * Tx1))/dx;\n",
    "    dy = dx\n",
    "    dtdy = ((-0.5 * T_y1) + (0.5 * Ty1))/dy;\n",
    "    \n",
    "    gam = 31.53 - (0.0855*T)\n",
    "    \n",
    "    gam_x1 = np.roll(gam, 1, axis = 1)\n",
    "    gamx1 = np.roll(gam, -1, axis = 1)\n",
    "    gam_y1 = np.roll(gam, 1, axis = 0)\n",
    "    gamy1 = np.roll(gam, -1, axis = 0)\n",
    "    \n",
    "    # if(build_plots):\n",
    "    #     plt.imshow(T, cmap = 'hot')\n",
    "    \n",
    "    for tr in range(1):\n",
    "        if(tr == 0):\n",
    "            dt = dt * dt_scaleFactor\n",
    "        \n",
    "        fluxX = np.zeros((200, 200))\n",
    "        fluxY = np.zeros((200, 200))\n",
    "        dfluxXdx = np.zeros((200, 200))\n",
    "        dfluxYdy = np.zeros((200, 200))\n",
    "        dhdt_max = 0\n",
    "        h = h0 * np.ones((200, 200))\n",
    "        status = 'incomplete'\n",
    "        \n",
    "        for r in range(num_iterations):\n",
    "        # for r in range(10):\n",
    "            # print('Enter num_iterations: ', r)\n",
    "            \n",
    "            h_x1 = np.roll(h, 1, axis = 1)\n",
    "            hx1 = np.roll(h, -1, axis = 1)\n",
    "            h_y1 = np.roll(h, 1, axis = 0)\n",
    "            hy1 = np.roll(h, -1, axis = 0)\n",
    "            \n",
    "            h_x2 = np.roll(h, 2, axis = 1)\n",
    "            hx2 = np.roll(h, -2, axis = 1)\n",
    "            h_y2 = np.roll(h, 2, axis = 0)\n",
    "            hy2 = np.roll(h, -2, axis = 0)\n",
    "            \n",
    "            fluxX_x1 = np.roll(fluxX, 1, axis = 1)\n",
    "            fluxXx1 = np.roll(fluxX, -1, axis = 1)\n",
    "            dfluxXdx_x1 = np.roll(dfluxXdx, 1, axis = 1)\n",
    "            dfluxXdxx1 = np.roll(dfluxXdx, -1, axis = 1)\n",
    "            \n",
    "            fluxY_y1 = np.roll(fluxY, 1, axis = 0)\n",
    "            fluxYy1 = np.roll(fluxY, -1, axis = 0)\n",
    "            dfluxY_y1 = np.roll(dfluxYdy, 1, axis = 0)\n",
    "            dfluxYy1 = np.roll(dfluxYdy, -1, axis = 0)\n",
    "            \n",
    "            dhdx2 = (h_x1 - (2 * h) + hx1)/(dx*dx)\n",
    "            dhdx3 = (((-0.5 * h_x2) + h_x1 - hx1 + (0.5 * hx2))/(dx*dx*dx))\n",
    "            \n",
    "            dhdy2 = (h_y1 - (2 * h) + hy1)/(dy*dy)\n",
    "            dhdy3 = (((-0.5 * h_y2) + h_y1 - hy1 + (0.5 * hy2))/(dy*dy*dy))\n",
    "            \n",
    "            deltah = dhdx2 + dhdy2\n",
    "            \n",
    "            deltahx1 = np.roll(deltah, -1, axis = 1)\n",
    "            deltahy1 = np.roll(deltah, -1, axis = 0)\n",
    "            deltah_x1 = np.roll(deltah, 1, axis = 1)\n",
    "            deltah_y1 = np.roll(deltah, 1, axis = 0)\n",
    "            \n",
    "            ddeltahdx = ((-0.5*deltah_x1) + (0.5*deltahx1))/dx\n",
    "            ddeltahdy = ((-0.5*deltah_y1) + (0.5*deltahy1))/dy\n",
    "            \n",
    "            fluxX = np.multiply(((np.square(h)*B)/(2*mu)), dtdx) + np.multiply(np.multiply((np.power(h, 3)/(3*mu)), dtdx), deltah) + np.multiply(np.multiply((np.power(h, 3)/(3*mu)), gam), ddeltahdx)\n",
    "            fluxY = np.multiply(((np.square(h)*B)/(2*mu)), dtdy) + np.multiply(np.multiply((np.power(h, 3)/(3*mu)), dtdy), deltah) + np.multiply(np.multiply((np.power(h, 3)/(3*mu)), gam), ddeltahdy)\n",
    "            \n",
    "            dfluxXdx = ((-0.5 * fluxX_x1) + (0.5 * fluxXx1))/dx\n",
    "            dflux = ((-0.5 * fluxY_y1) + (0.5 * fluxYy1))/dy\n",
    "            \n",
    "            dhdt = (-1 * dfluxXdx) + (-1 * dfluxYdy)\n",
    "            \n",
    "            if(dhdt_max > 10000000):\n",
    "                status = 'failed'\n",
    "                print('Failed')\n",
    "                break\n",
    "                \n",
    "            if(dhdt.flat[np.abs(dhdt).argmax()]   > dhdt_max):\n",
    "                dhdt_max = dhdt.flat[np.abs(dhdt).argmax()]\n",
    "                # print('dhdt_max: ', dhdt_max)\n",
    "                \n",
    "            # if(dhdt.flat[np.abs(dhdt).argmax()] < (dhdt_max * 0.01)):\n",
    "            #     print('Falied 2')\n",
    "            #     break\n",
    "                \n",
    "            h = h + (dhdt * dt)\n",
    "            \n",
    "            for m in range(len(h)):\n",
    "                for n in range(len(h[m])):\n",
    "                    if(h[m][n]<0):\n",
    "                        h[m][n] = 0\n",
    "                        \n",
    "#             if True in np.isnan(fluxX):\n",
    "#                 print('NaN value found in iteration: ', r)\n",
    "#                 break\n",
    "                        \n",
    "            if(build_plots and str(r)[-1] == '0'):\n",
    "                plt.imshow(h, cmap = 'hot')\n",
    "                plt.title('Height map Iteration: ' + str(r))\n",
    "                plt.colorbar()\n",
    "                plt.show()\n",
    "                clear_output(wait = True)\n",
    "\n",
    "    # Write T data    \n",
    "    t_filename = 'temp/T_' + str(file_count) + '.csv'\n",
    "    np.savetxt(t_filename, T, delimiter = \",\")    \n",
    "    \n",
    "    # Write h data\n",
    "    h_filename = 'temp/h_' + str(file_count) + '.csv'\n",
    "    np.savetxt(h_filename, h, delimiter = \",\") \n",
    "    \n",
    "    print('File ', file_count, ' done!')\n",
    "    print('Iterations done: ', r)\n",
    "    \n",
    "    file_count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56849759-fe10-4991-b80a-46d6311bbb70",
   "metadata": {},
   "source": [
    "<h2>CSV -> PT</h2>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d77a24-3905-46da-b0b9-3307ebb24b6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
